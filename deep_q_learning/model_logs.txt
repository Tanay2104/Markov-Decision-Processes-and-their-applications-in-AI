This files contains the trained model(s) parameters and hyperparameters
Model hyperparameters
Learning Rate: 0.0001, Epochs: 30, Gamma: 0.995, Batch Size: 64 Initial Epsilon: 1.0, Final Epsilon: 0.01, epsilon decay rate: 0.99997
Layer 0 weights:
 [[ 3.11320845e-02 -6.94447482e-02 -1.37092939e+00 -6.36094516e-01
   6.66183881e-01 -1.09988084e+00 -1.83852346e+00  1.12819142e+00
  -2.02974996e-01 -1.05170863e+00 -8.38798252e-01  3.00135931e+00
   7.18687180e-01 -5.57231711e-01  1.05757722e+00 -2.65757418e-01
  -8.53031807e-01 -9.74046670e-01  1.27212450e-01  1.67406134e+00
   8.07989679e-02 -3.50999402e-01  2.34007386e-01 -1.15743056e+00
   7.80661190e-01  4.13577613e-01 -8.00022124e-02  3.12798280e-02
  -2.75423722e-01  5.39923196e-01 -1.34416200e+00 -7.36859384e-01
  -1.59668273e+00 -7.58846631e-01 -2.42876658e-01  8.90528426e-01
   2.39682869e-01  5.67464826e-01  7.93890545e-01  1.03878601e-01
   3.33072606e+00  3.30689206e-01 -8.00539694e-01 -8.73742559e-01
  -1.14733666e+00 -4.17759481e-01  7.34011204e-01 -1.01367061e+00
  -2.42304571e-01 -8.60044163e-01 -7.93613458e-01  1.26690909e+00
   3.38887062e-01  1.33448164e+00  2.12770310e-01 -3.89407396e-01
  -7.62046283e-01 -2.42826698e-01  6.05553239e-01  6.00068355e-01
   3.74455398e-01 -7.73906972e-01  1.65502238e-02 -9.39347279e-01]
 [-2.50247441e-01 -5.29860977e-01 -1.25069297e+00 -1.73427443e+00
   2.08258153e+00 -4.70904588e-02 -1.27459800e+00  3.72507534e-01
  -1.16934314e+00 -4.76101986e-01 -4.11984750e-01  4.85624761e-01
  -2.04164836e-01 -1.98468285e-01 -9.35059431e-01 -5.15271721e-01
   2.16291648e+00  3.90016040e-01 -1.30142506e+00 -8.25024275e-01
  -1.04789165e+00 -1.72644765e+00  8.19067457e-02  1.85999205e+00
   3.86869952e-01  7.76763611e-01 -1.68193809e+00  8.89519941e-01
  -7.74309606e-01 -9.80555030e-01 -4.71144954e-01  3.75019171e-01
   5.40397865e-01  7.23129671e-02 -5.18888499e-01  3.67003339e-01
  -1.46151573e+00  1.63665080e-01 -5.63729415e-02 -3.32145426e+00
   1.62897724e+00  9.55741211e-02  4.39598065e-01 -7.77630490e-01
  -1.10178939e-01  5.50986469e-01  8.71490720e-02 -1.59300164e+00
  -1.97031150e+00  1.68217925e-01  7.01065730e-01  1.38553449e+00
  -3.09162843e-01  4.14170833e-01 -5.26256131e-01 -8.20815136e-01
   1.61406604e-01 -4.23176031e-01 -4.67736700e-01  7.94697742e-01
   1.42261574e+00  7.51461471e-01  1.48304512e+00 -1.80932443e+00]
 [-3.35071547e+00 -4.87704247e-01 -2.52462691e-01 -4.57849960e-01
   7.67799071e-01 -1.65479665e-01  2.09050108e+00  2.45948253e+00
  -3.30908959e-01  1.47340951e+00 -2.45034167e-01  6.85110739e-01
  -1.47715909e+00 -1.34997409e+00  4.50878472e-01  6.89803813e-02
   1.15705512e+00 -4.00333151e-02 -1.08288209e+00 -6.58436760e-02
  -5.21805688e-01 -3.52299915e-02  1.36842993e+00  1.13058971e+00
   2.07871736e-01  1.16395033e-01  9.25435512e-01 -9.00162616e-01
  -5.53010817e-01 -4.19213355e-01  7.90131251e-01 -1.95892998e-01
   1.33232513e+00 -5.88650023e-01  1.16235258e+00 -9.54431317e-01
  -1.41990931e+00 -3.53818574e-01 -1.66236376e+00  9.57973987e-01
   2.33463757e+00 -5.69108504e-01  1.42542424e-01 -7.21034660e-01
   1.22097041e+00  2.81302851e-01 -1.17463130e-01  6.55208161e-01
   1.02304754e-01 -2.29895545e-01 -1.72200041e+00  4.52381358e-01
   1.41617095e+00 -1.19321622e+00 -8.55425429e-01  6.12105820e-01
   2.82924725e-01  4.53199953e-01  2.16329174e-01 -7.68943100e-02
  -8.94008821e-02 -6.59821055e-01  1.11799112e+00 -5.62174390e-02]
 [ 8.71375946e-03  5.13829723e-01  4.50342086e-01  9.33770419e-01
  -1.40114161e-01 -7.71509610e-01 -8.55001809e-01 -3.60425030e-01
  -1.65065533e+00 -1.35325981e+00 -1.30405834e+00  4.59987836e-01
   6.35375642e-01 -4.88164055e-01  6.11314227e-01  1.38353589e-01
   1.34788740e-01  1.46819408e+00  1.61023745e+00  9.65385066e-01
   5.75127026e-02 -4.21624205e-01  6.11583460e-01  1.12583552e+00
  -6.02863343e-01 -5.56310381e-01 -6.24425320e-01 -4.25398646e-01
  -2.73733544e-01  1.50125825e+00  1.54319383e+00  8.02086188e-01
  -9.11388464e-01  7.19408977e-01  2.45692891e-01 -1.09294758e+00
   1.02424824e+00  1.12070124e+00 -5.62689065e-01  1.62823171e+00
  -4.40581361e-01  1.09949303e+00  9.14474747e-01  7.62217481e-01
  -1.61028312e-01  3.63950522e-01 -7.76864276e-01 -2.30090186e-02
  -6.29781694e-01 -1.07018633e+00 -1.69152796e-01  1.38403472e+00
  -2.32899079e-01  1.20202688e+00 -8.78212072e-01  5.51773908e-01
  -1.74396071e+00  1.82020065e-01  3.24405774e-01  5.99249979e-01
  -5.69418259e-01  2.52995565e-01  1.07774364e+00  3.00404595e+00]
 [ 3.05096106e-01 -1.39596628e+00 -1.12566022e+00  7.17824022e-01
   3.57136054e-01 -3.30086755e-01  1.24784204e+00 -1.27612523e+00
   5.31183096e-01 -1.16609102e+00 -1.82845108e+00 -7.87354547e-01
   4.77015663e-01  1.73027817e+00  6.69035754e-01 -1.62227925e+00
   1.68119860e+00  7.31699355e-01  2.49187564e-01 -1.00647728e+00
  -2.55102856e-01 -4.53207522e-02  1.23061467e+00 -5.53804436e-01
  -5.45280021e-01 -4.55278199e-01  6.47195493e-01  3.14537161e-01
  -1.47734338e+00 -8.08932286e-01 -8.05392853e-01  2.88664687e-01
  -1.02057388e-01 -5.87528066e-01 -2.31972622e-01 -3.95403710e-01
  -7.86162773e-01  2.43713141e-01  1.29109402e+00  1.50659896e-01
   2.06782053e+00  1.05669297e+00 -6.10030059e-01  5.79178248e-01
   6.11672866e-01  3.57791102e-01  8.89018907e-01 -1.23360133e+00
   7.49479553e-01  8.13978408e-01 -6.16465949e-01  4.11659621e-01
  -1.25312668e+00  5.03455833e-01  1.30220629e+00  7.96153295e-01
   2.15588514e-01  9.99445704e-01  5.03313823e-01 -2.23778799e-01
  -2.93541340e-01 -1.82459199e-01 -6.52288267e-01 -1.25127900e-01]
 [ 1.30318819e+00 -5.89809049e-01 -1.92262358e+00 -1.06710434e+00
   2.48868529e-01 -2.28465852e+00  8.36836979e-02  1.48376463e+00
  -1.38946530e-01  7.73650320e-01  9.66458717e-01 -9.42611587e-02
   1.98200683e+00  8.62213365e-01  8.78736699e-01 -3.60822837e-01
  -3.77241768e-01 -8.85714007e-01  6.76667997e-01 -1.45228980e+00
  -6.66558516e-01 -8.85502022e-02 -5.85834098e-02 -3.46454072e-01
  -1.99777228e+00 -1.20583969e+00  4.89198287e-01  1.06433485e+00
   1.65861079e-01  6.98172780e-01  3.32061656e-01  4.05690149e-01
  -1.62701475e+00  1.29395594e+00  1.92254930e+00  1.44174764e-01
  -7.17057594e-01 -1.04993793e+00 -1.59158738e-01 -3.17990686e-01
  -5.48581797e-01  1.56617334e+00  1.14353051e+00  3.50610975e-02
  -1.33377119e+00 -1.86264866e-01 -1.06285621e+00 -1.24371644e+00
   3.17936615e-01 -1.47875504e+00  3.44736575e-01 -9.90707194e-01
  -1.88935383e+00  8.99372413e-01 -5.53744731e-01 -7.78453925e-01
  -4.48205668e-01  5.53247746e-01  2.44451684e+00 -9.36944644e-01
   9.09981469e-01 -1.31524913e+00  7.13109368e-01  1.02678090e+00]
 [ 5.80325060e-02  3.69741413e-01 -2.88074313e-01  1.35670635e+00
   2.05721791e+00 -1.72031502e+00  1.01380218e+00 -1.62724839e-01
   4.59342920e-01  1.77016264e+00 -1.46450145e+00  1.64777795e+00
   1.80109550e+00 -1.65346019e+00  7.57571480e-02  6.79084649e-01
   4.13700842e-01  1.47116053e+00 -4.29904987e-01 -1.16069752e+00
   1.47083627e+00 -1.10798701e+00 -3.29808007e-01  5.78997635e-04
  -4.33549359e-01 -6.99620938e-01  7.01431853e-01  2.58871145e-01
   1.09082408e+00 -1.66209290e-01 -2.10152206e+00  1.35807357e+00
  -2.41892174e-01 -4.39577129e-01  1.30783539e+00 -6.48442513e-01
   4.82427408e-01  1.37600620e+00 -3.89504182e-01 -4.44147287e-01
  -8.76986715e-01 -9.95931352e-01  4.97928371e-02  2.40960777e-02
  -1.10663392e+00 -4.75110290e-02  1.70570801e+00 -1.32666106e+00
  -4.66729345e-01 -2.59362754e+00 -1.83841135e+00 -6.05739849e-01
  -1.09645303e+00  3.35600072e-01 -1.70730011e+00 -1.88748839e+00
  -5.20795421e-01  2.42939118e+00  6.95419261e-02  5.24227473e-01
  -1.58802346e+00 -4.25071663e-01 -8.34862047e-01  1.43002798e+00]
 [-2.21638724e-01 -8.18340881e-01  5.87022934e-01 -2.21011137e-01
  -9.18829231e-02 -2.30691232e-01 -7.47516653e-01  2.42678282e-01
  -1.16706840e+00 -2.47300828e+00 -9.02927005e-01  8.22349339e-01
   1.43350042e+00  2.46292837e-01 -4.00432399e-01  4.45991486e-01
   1.60051505e+00 -5.42925127e-01 -1.27754611e+00 -1.14594096e+00
   3.69547255e-01  8.83910202e-01 -9.59489661e-01 -5.09874965e-01
  -1.09798359e-03  1.80617597e-01 -9.74057251e-01 -7.28277188e-01
  -3.66955227e-01  5.31655773e-01  1.67380103e+00 -1.84326116e+00
   1.80552362e+00 -1.03910888e+00  1.59785154e+00 -5.31537672e-01
   1.45929045e+00  1.13930056e-01  1.04619206e+00 -1.20871264e+00
  -1.01453949e+00  3.02987690e-01  1.22398435e+00  5.60311857e-02
  -3.12827279e-01 -5.47844611e-01 -1.95416491e-01  2.56404507e-01
   1.78702516e+00  1.57017221e-01 -8.21864839e-01  2.93725087e-01
  -1.25106395e+00 -1.39263475e+00  1.25200372e+00 -2.70948275e-01
   5.86309461e-01  3.25668414e-01 -1.37447242e+00  6.21943411e-01
   9.48121034e-01 -1.01845801e+00 -2.54392490e+00 -1.38919298e-01]]Layer 0 biases:
 [-0.23820856  0.01202699 -0.04930823 -0.0391608   0.06711756 -0.00793828
 -0.01483191 -0.12473856 -0.34175443  0.13767603  0.13446072  0.00175941
 -0.39195359 -0.03058588 -0.02660047 -0.03862321  0.23170601  0.000917
  0.02512872 -0.04934516 -0.07044431 -0.03165559  0.13318188 -0.04048944
 -0.17695597 -0.00911887 -0.00740739  0.20369743 -0.13084363 -0.00443804
 -0.05535728  0.09942175  0.25361657 -0.02495367 -0.01531528  0.22128599
  0.00099569  0.03951459  0.01450962  0.00042074  0.05127927  0.13189733
  0.09573212  0.01419068 -0.13091445 -0.09199782 -0.0250533  -0.0812047
 -0.14037118  0.23708736  0.35082741 -0.084581   -0.306319   -0.06093431
 -0.01977565 -0.00313791  0.18761431 -0.07889174  0.11198616  0.01041689
 -0.152579    0.04777158 -0.03992287 -0.04531143]Layer 0 has activation function ReLULayer 1 weights:
 [[-0.14497096  1.69361577 -0.41269823 ...  0.31474969  2.62335208
  -0.16282905]
 [-0.59263064  1.01729069  0.30881002 ... -0.38768915 -0.02458271
   1.83908603]
 [-0.16402011 -0.68432272  0.0111343  ...  0.71471298 -0.40886607
  -0.56521854]
 ...
 [-0.37709525 -0.47641216 -0.27243698 ... -0.53515186 -1.41825995
  -0.74319696]
 [ 0.66244365  1.2108412  -2.02873632 ... -1.18268579 -0.0425269
  -1.0327304 ]
 [ 3.13597433 -0.83514701 -0.5263769  ...  0.21924489 -1.34529926
  -0.92199081]]Layer 1 biases:
 [-0.02396893 -0.00299117 -0.00205436  0.04038663 -0.04883375 -0.00196555
 -0.01847837 -0.00896705 -0.00327245 -0.07199274 -0.00069071  0.00928541
  0.00049898 -0.00708512 -0.01607153  0.00381954 -0.00188878  0.03054827
 -0.0479662   0.0184816   0.02054586  0.00168835  0.00625375  0.01121564
  0.00732225  0.00740526 -0.00924008  0.0387303  -0.00674385  0.01274091
 -0.02081838 -0.03413366 -0.02009527  0.01991772  0.00589273 -0.02811667
  0.0175642   0.00110415 -0.0100539  -0.02977365 -0.03267923  0.05378254
 -0.03328592  0.02601909 -0.00419577 -0.00754283 -0.00027932  0.0408488
 -0.00099765  0.00711647  0.06123957 -0.01333501 -0.01523001 -0.00580115
 -0.00928428 -0.00217041  0.00563502 -0.00736717 -0.01227957 -0.00231734
 -0.06026075  0.00872627 -0.00307367  0.00206514]Layer 1 has activation function ReLULayer 2 weights:
 [[-1.24411772  0.07266551 -0.60860483  0.31763897]
 [ 0.44140857  0.19772165 -0.58645016  0.45905673]
 [ 0.8271773  -0.73440909 -0.50145157  0.71736228]
 [-0.20470826  1.36172704  1.00455044  1.60912219]
 [-1.52302117 -0.64740372 -0.25653548  0.70444259]
 [-0.09350372  1.63475094  0.14833025 -0.1609145 ]
 [-0.25878772 -0.62599131  0.87777537 -0.39747858]
 [ 0.51515002 -0.8572847   0.83795483  1.61394481]
 [-0.3586832   0.10483158  0.37490611 -1.32701546]
 [-1.1643402  -0.09364991 -3.5107341  -2.11479334]
 [-1.56063933 -0.49396961 -0.71342107  1.31583558]
 [ 0.10871941 -0.88779154  0.54135111  0.35160488]
 [-1.61052212  1.25600401  0.09532703 -0.90519156]
 [ 0.39113429 -1.32169702 -1.00549769 -0.61163443]
 [-0.21681139  0.38559448 -1.00027053  1.94877898]
 [-0.58207409  0.49401079  1.04518602 -0.6961963 ]
 [-1.05792728  0.41634217  0.38762491 -0.84279261]
 [-0.0571661   0.50206472  0.61406784 -1.29948714]
 [-0.14408087 -1.05395582  0.72768935 -1.28694515]
 [ 0.26766639  1.0187876  -0.86362433  0.48633091]
 [ 1.02626352 -0.37843453  1.24889988 -0.91894208]
 [ 0.54402004 -0.27760334 -0.54665081 -3.54103147]
 [-1.13833962 -0.30581259 -0.07612298 -0.6304565 ]
 [ 0.48300339 -0.84165571  2.32814332  1.58757878]
 [-0.89108847 -0.0896932   1.21976144  1.19406418]
 [ 0.91371707  0.12991232 -0.43478963  0.72988992]
 [-0.31280121  0.31159424 -0.32529992  0.69556569]
 [-0.05120687  0.56683643  1.20112901  2.24682649]
 [ 1.27144654 -0.33879398 -1.05575279  1.00407851]
 [ 2.64403959 -1.209696    0.90075011 -0.54191398]
 [-1.62874159  1.60958493 -0.50068232 -0.64385357]
 [-0.85177666 -0.64060872  1.07688061  0.08351468]
 [-2.48909577 -0.70527664  0.25243816 -1.10361141]
 [ 1.45215064  1.36087338  0.98890027  1.26561843]
 [ 1.24532309 -0.63250579  0.23018046 -0.09036012]
 [-1.1483879  -0.65930019  0.64573191 -0.54978887]
 [ 1.36231087 -0.2013539  -0.78197989  2.02276646]
 [-0.50637217 -0.75673884  1.27623774  0.07817512]
 [ 0.67393312  0.80462413 -0.43414862 -0.24776676]
 [ 0.1404591  -1.86383747 -0.40649114 -1.12136411]
 [ 0.04863154 -0.64367992  1.0345291  -0.1349295 ]
 [ 1.14476322  0.28288855  0.70621451  0.41199703]
 [ 0.32437041 -0.71298486 -0.52759583  0.12506521]
 [ 0.57763004  0.86361404 -0.41263728  0.08581036]
 [-1.17602953  1.2695479  -0.80392139  0.31940527]
 [ 0.14059094  0.22820286 -0.46251279 -1.27621405]
 [-0.45319709 -1.00504638  0.28664341  0.77839733]
 [-0.37822104  1.08944206  1.03237542  1.60183252]
 [ 0.60254261  0.47019493 -0.46670625  0.25431827]
 [-0.53401231 -0.24142642 -0.15833654 -0.98493049]
 [ 1.17744482  1.40260127 -0.00618952  0.18205898]
 [ 1.18408558 -1.31933298  0.14051256  1.23974596]
 [-0.4583312   0.67958032 -1.11667225 -0.41927709]
 [ 0.33655934 -1.34155701 -0.33189206  0.36021411]
 [-0.76775246  0.4191031  -0.75982685 -0.63279498]
 [ 1.44364467  0.86609044  0.85629236  0.48814693]
 [ 0.29770804  0.03790873  0.88762753  0.10630627]
 [-0.05059385  0.35214013 -1.01409719  2.13354312]
 [-0.38988771 -1.16321631 -0.30020811  0.9921362 ]
 [-0.35517695  0.14797555  0.10399525 -0.13958488]
 [-0.14857351 -0.97777219 -0.23174226 -0.43269922]
 [-0.43954035 -0.31070157  1.5170354  -0.16024139]
 [-1.13897443  1.62961969 -0.96721339 -0.33716169]
 [ 0.24793374 -0.23074574  0.35263711 -1.07981417]]Layer 2 biases:
 [0.0260346  0.03620715 0.02128229 0.00341902]Layer 2 has activation function Linear-----
